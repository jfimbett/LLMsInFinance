{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5d5af0d",
   "metadata": {},
   "source": [
    "# Day 1 Practical Session: Environment Setup\n",
    "\n",
    "Welcome to the practical session for Day 1! In this notebook, we'll set up our Python environment and ensure everything is working correctly for LLM applications.\n",
    "\n",
    "## Learning Objectives\n",
    "- Set up a Python environment suitable for LLM applications\n",
    "- Install essential packages for working with LLMs\n",
    "- Test the environment with basic imports\n",
    "- Understand best practices for environment management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ca586a",
   "metadata": {},
   "source": [
    "## 1. Environment Setup Overview\n",
    "\n",
    "For this course, we'll be working with several key Python packages:\n",
    "\n",
    "- **transformers**: HuggingFace's library for pre-trained models\n",
    "- **torch**: PyTorch for deep learning\n",
    "- **openai**: Official OpenAI API client\n",
    "- **python-dotenv**: For managing environment variables\n",
    "- **pandas**: For data manipulation\n",
    "- **matplotlib/seaborn**: For visualization\n",
    "- **jupyter**: For interactive notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0b6025",
   "metadata": {},
   "source": [
    "## 2. Installing Required Packages\n",
    "\n",
    "If you haven't already, install the required packages. Run the following cell to install them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781435ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# Note: Run this cell only once, or if you need to update packages\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"âœ… {package} installed successfully\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"âŒ Failed to install {package}\")\n",
    "\n",
    "# Essential packages for LLM work\n",
    "packages = [\n",
    "    \"torch>=2.0.0\",\n",
    "    \"transformers>=4.30.0\",\n",
    "    \"datasets>=2.12.0\",\n",
    "    \"accelerate>=0.20.0\",\n",
    "    \"python-dotenv>=1.0.0\",\n",
    "    \"openai>=1.0.0\",\n",
    "    \"pandas>=2.0.0\",\n",
    "    \"matplotlib>=3.7.1\",\n",
    "    \"seaborn>=0.12.0\",\n",
    "    \"requests>=2.28.0\"\n",
    "]\n",
    "\n",
    "# Uncomment the following lines to install packages\n",
    "# for package in packages:\n",
    "#     install_package(package)\n",
    "\n",
    "print(\"\\nğŸ“ To install manually, run:\")\n",
    "print(\"pip install \" + \" \".join(packages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5a8322",
   "metadata": {},
   "source": [
    "## 3. Testing Your Environment\n",
    "\n",
    "Let's test that all the essential packages are installed and working correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d440d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test essential imports\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\\n\")\n",
    "\n",
    "# Test each package\n",
    "packages_to_test = {\n",
    "    'torch': 'PyTorch',\n",
    "    'transformers': 'HuggingFace Transformers',\n",
    "    'openai': 'OpenAI API Client',\n",
    "    'pandas': 'Pandas',\n",
    "    'matplotlib': 'Matplotlib',\n",
    "    'requests': 'Requests',\n",
    "    'dotenv': 'Python-dotenv'\n",
    "}\n",
    "\n",
    "for package, name in packages_to_test.items():\n",
    "    try:\n",
    "        if package == 'dotenv':\n",
    "            import python_dotenv as dotenv\n",
    "            version = dotenv.__version__\n",
    "        else:\n",
    "            module = __import__(package)\n",
    "            version = getattr(module, '__version__', 'Unknown')\n",
    "        print(f\"âœ… {name}: {version}\")\n",
    "    except ImportError:\n",
    "        print(f\"âŒ {name}: Not installed\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ {name}: Error - {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552c0595",
   "metadata": {},
   "source": [
    "## 4. Check GPU Availability (Optional)\n",
    "\n",
    "While not required for this course, having GPU access can speed up model inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebc34b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"ğŸ” GPU Information:\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"No GPU available - will use CPU (this is fine for most exercises)\")\n",
    "\n",
    "# Check MPS (Apple Silicon) availability\n",
    "if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    print(\"ğŸ Apple MPS (Metal Performance Shaders) available\")\n",
    "else:\n",
    "    print(\"ğŸ Apple MPS not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dc3fd3",
   "metadata": {},
   "source": [
    "## 5. Create Requirements File\n",
    "\n",
    "Let's create a requirements.txt file for easy environment reproduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de9b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create requirements.txt file\n",
    "requirements_content = \"\"\"# LLMs in Finance Course - Requirements\n",
    "# Core ML and NLP packages\n",
    "torch>=2.0.0\n",
    "transformers>=4.30.0\n",
    "datasets>=2.12.0\n",
    "accelerate>=0.20.0\n",
    "sentencepiece>=0.1.99\n",
    "tokenizers>=0.13.0\n",
    "\n",
    "# API clients\n",
    "openai>=1.0.0\n",
    "anthropic>=0.18.0\n",
    "\n",
    "# Environment and configuration\n",
    "python-dotenv>=1.0.0\n",
    "\n",
    "# Data manipulation and analysis\n",
    "pandas>=2.0.0\n",
    "numpy>=1.24.0\n",
    "\n",
    "# Visualization\n",
    "matplotlib>=3.7.1\n",
    "seaborn>=0.12.0\n",
    "plotly>=5.14.0\n",
    "\n",
    "# Utilities\n",
    "requests>=2.28.0\n",
    "tqdm>=4.65.0\n",
    "scikit-learn>=1.2.2\n",
    "\n",
    "# Jupyter and notebook support\n",
    "jupyter>=1.0.0\n",
    "ipywidgets>=8.0.0\n",
    "\"\"\"\n",
    "\n",
    "# Write to file\n",
    "with open('requirements.txt', 'w') as f:\n",
    "    f.write(requirements_content)\n",
    "\n",
    "print(\"ğŸ“„ Created requirements.txt file\")\n",
    "print(\"\\nTo install all requirements in a new environment:\")\n",
    "print(\"pip install -r requirements.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6596d36c",
   "metadata": {},
   "source": [
    "## 6. Environment Validation Test\n",
    "\n",
    "Let's run a comprehensive test to ensure everything is working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e1b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive environment test\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ğŸ§ª Running comprehensive environment test...\\n\")\n",
    "\n",
    "# Test 1: Basic data manipulation\n",
    "print(\"1ï¸âƒ£ Testing data manipulation...\")\n",
    "df = pd.DataFrame({\n",
    "    'text': ['This is positive', 'This is negative', 'This is neutral'],\n",
    "    'sentiment': ['positive', 'negative', 'neutral']\n",
    "})\n",
    "print(f\"   Created DataFrame with {len(df)} rows âœ…\")\n",
    "\n",
    "# Test 2: Basic visualization\n",
    "print(\"\\n2ï¸âƒ£ Testing visualization...\")\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "ax.bar(df['sentiment'], [1, 1, 1])\n",
    "ax.set_title('Test Plot')\n",
    "plt.close()  # Close to avoid showing\n",
    "print(\"   Created test plot âœ…\")\n",
    "\n",
    "# Test 3: HuggingFace pipeline (lightweight)\n",
    "print(\"\\n3ï¸âƒ£ Testing HuggingFace pipeline...\")\n",
    "try:\n",
    "    # Use a very small model for testing\n",
    "    classifier = pipeline(\n",
    "        \"sentiment-analysis\", \n",
    "        model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "        return_all_scores=False\n",
    "    )\n",
    "    result = classifier(\"This is a test\")\n",
    "    print(f\"   Pipeline test result: {result} âœ…\")\n",
    "except Exception as e:\n",
    "    print(f\"   Pipeline test failed: {e} âŒ\")\n",
    "    print(\"   This might be due to network issues or missing dependencies\")\n",
    "\n",
    "print(\"\\nğŸ‰ Environment test complete!\")\n",
    "print(\"\\nğŸ“ Next steps:\")\n",
    "print(\"   - Set up version control (Git)\")\n",
    "print(\"   - Create .env file for API keys\")\n",
    "print(\"   - Test API connections\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4fe6d7",
   "metadata": {},
   "source": [
    "## 7. Best Practices Summary\n",
    "\n",
    "### Environment Management\n",
    "- Always use virtual environments for projects\n",
    "- Keep a `requirements.txt` file updated\n",
    "- Pin package versions for reproducibility\n",
    "- Document any special installation steps\n",
    "\n",
    "### Project Structure\n",
    "```\n",
    "llm-finance-project/\n",
    "â”œâ”€â”€ .env                 # API keys (DO NOT COMMIT)\n",
    "â”œâ”€â”€ .gitignore          # Git ignore file\n",
    "â”œâ”€â”€ requirements.txt    # Package dependencies\n",
    "â”œâ”€â”€ README.md          # Project documentation\n",
    "â”œâ”€â”€ notebooks/         # Jupyter notebooks\n",
    "â”œâ”€â”€ src/              # Source code\n",
    "â””â”€â”€ data/             # Data files\n",
    "```\n",
    "\n",
    "### Next Steps\n",
    "1. Set up version control with Git\n",
    "2. Create and configure `.env` file for API keys\n",
    "3. Test API connections to OpenAI and DeepSeek\n",
    "4. Explore HuggingFace models locally"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
