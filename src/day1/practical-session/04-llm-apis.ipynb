{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b12e1b6",
   "metadata": {},
   "source": [
    "# Accessing LLMs through APIs\n",
    "\n",
    "In this notebook, we'll learn how to access powerful Large Language Models (LLMs) through their respective APIs. This is often the most practical approach for using state-of-the-art models without the computational overhead of running them locally.\n",
    "\n",
    "## Learning Objectives\n",
    "- Set up API keys securely using environment variables\n",
    "- Understand best practices for API key management (using .env and .gitignore)\n",
    "- Connect to OpenAI's models (like GPT-4)\n",
    "- Connect to DeepSeek's models\n",
    "- Perform basic text generation, chat, and completion tasks\n",
    "- Compare results across different providers and models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6d8e94",
   "metadata": {},
   "source": [
    "## 1. API Key Management: Best Practices\n",
    "\n",
    "When working with LLM APIs, you'll need to manage API keys securely. Here's how to do it properly:\n",
    "\n",
    "### Why API Key Security Matters\n",
    "- API keys provide access to paid services (costs can accumulate)\n",
    "- Keys can be misused if stolen or leaked\n",
    "- Most services have rate limits and quotas tied to keys\n",
    "- Companies may require internal security compliance\n",
    "\n",
    "### Secure API Key Management\n",
    "1. **NEVER hardcode API keys in your code**\n",
    "2. **NEVER commit API keys to version control**\n",
    "3. **ALWAYS use environment variables or config files outside version control**\n",
    "4. **Set appropriate usage limits on your API keys**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8f0253",
   "metadata": {},
   "source": [
    "## 2. Setting Up Environment Variables\n",
    "\n",
    "We'll use the `.env` file pattern with the `python-dotenv` library:\n",
    "\n",
    "1. Create a `.env` file to store your API keys\n",
    "2. Add the `.env` file to your `.gitignore`\n",
    "3. Use `python-dotenv` to load the environment variables\n",
    "\n",
    "Let's set up a `.env` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74356cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, check if python-dotenv is installed\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    import dotenv\n",
    "    print(f\"âœ… python-dotenv is installed (version: {dotenv.__version__})\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ python-dotenv not found. Installing...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"python-dotenv\"])\n",
    "    import dotenv\n",
    "    print(f\"âœ… python-dotenv installed (version: {dotenv.__version__})\")\n",
    "\n",
    "# Create a .env.example file (this is safe to commit)\n",
    "env_example = \"\"\"# API Keys for LLM Services\n",
    "# Copy this file to .env and fill in your API keys\n",
    "# NEVER commit your .env file to version control!\n",
    "\n",
    "# OpenAI API\n",
    "OPENAI_API_KEY=your_openai_api_key_here\n",
    "\n",
    "# DeepSeek API\n",
    "DEEPSEEK_API_KEY=your_deepseek_api_key_here\n",
    "DEEPSEEK_API_BASE=https://api.deepseek.com/v1\n",
    "\n",
    "# Optional: Other API providers\n",
    "ANTHROPIC_API_KEY=your_anthropic_api_key_here\n",
    "COHERE_API_KEY=your_cohere_api_key_here\n",
    "\n",
    "# Model Configuration\n",
    "DEFAULT_MODEL=gpt-3.5-turbo\n",
    "MAX_TOKENS=1000\n",
    "TEMPERATURE=0.7\n",
    "\"\"\"\n",
    "\n",
    "with open('.env.example', 'w') as f:\n",
    "    f.write(env_example)\n",
    "    \n",
    "print(\"ðŸ“„ Created .env.example file\")\n",
    "print(\"â„¹ï¸  This file is a template and safe to commit to version control\")\n",
    "\n",
    "# Check if .env exists, create if not\n",
    "import os\n",
    "if not os.path.exists('.env'):\n",
    "    print(\"\\nâš ï¸ No .env file found. Creating from example...\")\n",
    "    with open('.env', 'w') as f:\n",
    "        f.write(env_example)\n",
    "    print(\"ðŸ“„ Created .env file\")\n",
    "    print(\"âš ï¸ Please edit the .env file with your actual API keys before proceeding\")\n",
    "else:\n",
    "    print(\"\\nâœ… .env file already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986c3652",
   "metadata": {},
   "source": [
    "## 3. Setting Up .gitignore\n",
    "\n",
    "To ensure your API keys aren't committed to version control, you need to add `.env` to your `.gitignore` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99cb8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or update .gitignore to include .env\n",
    "gitignore_content = \"\"\"\n",
    "# API Keys and Environment Variables\n",
    ".env\n",
    "*.env\n",
    ".env.local\n",
    "\n",
    "# Python\n",
    "__pycache__/\n",
    "*.py[cod]\n",
    "*$py.class\n",
    "*.so\n",
    ".Python\n",
    "env/\n",
    "build/\n",
    "develop-eggs/\n",
    "dist/\n",
    "downloads/\n",
    "eggs/\n",
    ".eggs/\n",
    "lib/\n",
    "lib64/\n",
    "parts/\n",
    "sdist/\n",
    "var/\n",
    "*.egg-info/\n",
    ".installed.cfg\n",
    "*.egg\n",
    "\n",
    "# Jupyter Notebook\n",
    ".ipynb_checkpoints\n",
    "\n",
    "# Virtual Environment\n",
    "venv/\n",
    "ENV/\n",
    "\n",
    "# IDE\n",
    ".idea/\n",
    ".vscode/\n",
    "*.swp\n",
    "*.swo\n",
    "\n",
    "# OS-specific\n",
    ".DS_Store\n",
    "Thumbs.db\n",
    "\"\"\"\n",
    "\n",
    "# Check if .gitignore exists and update it\n",
    "gitignore_path = '.gitignore'\n",
    "if os.path.exists(gitignore_path):\n",
    "    # Read existing content\n",
    "    with open(gitignore_path, 'r') as f:\n",
    "        existing_content = f.read()\n",
    "    \n",
    "    # Check if .env is already in .gitignore\n",
    "    if '.env' in existing_content:\n",
    "        print(\"âœ… .env is already in .gitignore\")\n",
    "    else:\n",
    "        # Append to existing .gitignore\n",
    "        with open(gitignore_path, 'a') as f:\n",
    "            f.write(\"\\n# API Keys and Environment Variables\\n.env\\n*.env\\n.env.local\\n\")\n",
    "        print(\"âœ… Added .env to existing .gitignore\")\n",
    "else:\n",
    "    # Create new .gitignore\n",
    "    with open(gitignore_path, 'w') as f:\n",
    "        f.write(gitignore_content)\n",
    "    print(\"ðŸ“„ Created .gitignore file with .env excluded\")\n",
    "\n",
    "print(\"\\nâš ï¸ IMPORTANT: .env file containing real API keys will NOT be committed to Git\")\n",
    "print(\"ðŸ‘‰ Only the .env.example template (without real keys) should be committed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6143203",
   "metadata": {},
   "source": [
    "## 4. Loading API Keys from Environment Variables\n",
    "\n",
    "Now, let's load our API keys from the .env file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9624b7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load variables from .env file into environment\n",
    "load_dotenv()\n",
    "\n",
    "# Get API keys from environment variables\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "deepseek_api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "deepseek_api_base = os.getenv(\"DEEPSEEK_API_BASE\", \"https://api.deepseek.com/v1\")\n",
    "\n",
    "# Function to check key validity (basic check)\n",
    "def check_api_key(key, provider):\n",
    "    if not key or key == f\"your_{provider}_api_key_here\":\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Check if API keys are available\n",
    "print(\"ðŸ”‘ API Key Status:\\n\")\n",
    "\n",
    "if check_api_key(openai_api_key, \"openai\"):\n",
    "    print(\"âœ… OpenAI API key found\")\n",
    "else:\n",
    "    print(\"âŒ OpenAI API key not found or not set\")\n",
    "    print(\"   Please edit your .env file and add your OpenAI API key\")\n",
    "    print(\"   Get a key at: https://platform.openai.com/api-keys\")\n",
    "\n",
    "if check_api_key(deepseek_api_key, \"deepseek\"):\n",
    "    print(\"âœ… DeepSeek API key found\")\n",
    "else:\n",
    "    print(\"âŒ DeepSeek API key not found or not set\")\n",
    "    print(\"   Please edit your .env file and add your DeepSeek API key\")\n",
    "    print(\"   Get a key at: https://platform.deepseek.com/\")\n",
    "\n",
    "print(\"\\nâ„¹ï¸ You can proceed with the sections for which you have valid API keys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4388d30",
   "metadata": {},
   "source": [
    "## 5. Connecting to OpenAI API\n",
    "\n",
    "Let's start with OpenAI, which provides models like GPT-3.5 and GPT-4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca74ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install OpenAI library if not already installed\n",
    "try:\n",
    "    import openai\n",
    "    print(f\"âœ… OpenAI library is installed (version: {openai.__version__})\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ OpenAI library not found. Installing...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"openai\"])\n",
    "    import openai\n",
    "    print(f\"âœ… OpenAI library installed (version: {openai.__version__})\")\n",
    "\n",
    "# Set up OpenAI client\n",
    "from openai import OpenAI\n",
    "\n",
    "# Skip if API key not found\n",
    "if not check_api_key(openai_api_key, \"openai\"):\n",
    "    print(\"âš ï¸ Skipping OpenAI examples due to missing API key\")\n",
    "else:\n",
    "    # Initialize the client\n",
    "    client = OpenAI(api_key=openai_api_key)\n",
    "    \n",
    "    print(\"ðŸš€ OpenAI API Connection Established\")\n",
    "    \n",
    "    # Get available models\n",
    "    try:\n",
    "        models = client.models.list()\n",
    "        print(\"\\nðŸ“‹ Available Models:\")\n",
    "        # Display only GPT models\n",
    "        gpt_models = [model.id for model in models.data if \"gpt\" in model.id.lower()]\n",
    "        for i, model in enumerate(sorted(gpt_models), 1):\n",
    "            print(f\"   {i}. {model}\")\n",
    "        \n",
    "        # Display counts by type\n",
    "        model_prefixes = {}\n",
    "        for model in models.data:\n",
    "            prefix = model.id.split(\"-\")[0]\n",
    "            model_prefixes[prefix] = model_prefixes.get(prefix, 0) + 1\n",
    "        \n",
    "        print(\"\\nðŸ“Š Model Families:\")\n",
    "        for prefix, count in model_prefixes.items():\n",
    "            print(f\"   {prefix}: {count} models\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error listing models: {e}\")\n",
    "        print(\"   This could be due to an invalid API key or connection issue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ad70a3",
   "metadata": {},
   "source": [
    "## 6. Basic Text Generation with OpenAI\n",
    "\n",
    "Let's perform some basic text generation tasks with OpenAI models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b653ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple text generation with OpenAI\n",
    "if not check_api_key(openai_api_key, \"openai\"):\n",
    "    print(\"âš ï¸ Skipping OpenAI examples due to missing API key\")\n",
    "else:\n",
    "    # Define a simple financial prompt\n",
    "    financial_prompt = \"Explain what an ETF is in simple terms and list three popular ones.\"\n",
    "    \n",
    "    print(\"ðŸ¤– Testing OpenAI Text Generation\\n\")\n",
    "    print(f\"Prompt: {financial_prompt}\\n\")\n",
    "    \n",
    "    # Default to gpt-3.5-turbo if no other model specified\n",
    "    model = os.getenv(\"DEFAULT_MODEL\", \"gpt-3.5-turbo\")\n",
    "    \n",
    "    try:\n",
    "        # Create a completion\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a financial expert providing clear and concise information.\"},\n",
    "                {\"role\": \"user\", \"content\": financial_prompt}\n",
    "            ],\n",
    "            max_tokens=300,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        # Display the response\n",
    "        print(f\"âœ… Response from {model}:\\n\")\n",
    "        print(response.choices[0].message.content)\n",
    "        \n",
    "        # Display token usage\n",
    "        print(\"\\nðŸ“Š Token Usage:\")\n",
    "        print(f\"   Prompt tokens: {response.usage.prompt_tokens}\")\n",
    "        print(f\"   Completion tokens: {response.usage.completion_tokens}\")\n",
    "        print(f\"   Total tokens: {response.usage.total_tokens}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98930520",
   "metadata": {},
   "source": [
    "## 7. Financial Analysis Example with OpenAI\n",
    "\n",
    "Let's try a more complex financial analysis task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee925b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Financial analysis example\n",
    "if not check_api_key(openai_api_key, \"openai\"):\n",
    "    print(\"âš ï¸ Skipping OpenAI examples due to missing API key\")\n",
    "else:\n",
    "    # Financial analysis prompt\n",
    "    financial_analysis_prompt = \"\"\"\n",
    "    Analyze the following quarterly financial data for a technology company:\n",
    "    \n",
    "    Revenue: $10.2B (up 12% YoY)\n",
    "    Operating Income: $3.8B (up 8% YoY)\n",
    "    Net Income: $2.9B (up 5% YoY)\n",
    "    EPS: $1.45 (up 7% YoY)\n",
    "    Cash Flow from Operations: $4.5B (up 15% YoY)\n",
    "    \n",
    "    Provide a brief analysis of the company's financial health and potential concerns. \n",
    "    Then recommend whether this would be a good investment based solely on this data.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ðŸ“ˆ Financial Analysis Example\\n\")\n",
    "    print(\"Prompt: Analyzing quarterly financial data for a tech company...\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Create a completion with more detailed system prompt\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\" if \"gpt-4\" in str(gpt_models) else \"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"\"\"You are a financial analyst with expertise in technology companies.\n",
    "                 Provide insightful analysis that considers growth rates, profitability, and cash flow.\n",
    "                 Be balanced, highlighting both strengths and potential concerns.\"\"\"},\n",
    "                {\"role\": \"user\", \"content\": financial_analysis_prompt}\n",
    "            ],\n",
    "            max_tokens=500,\n",
    "            temperature=0.5  # Lower temperature for more focused analysis\n",
    "        )\n",
    "        \n",
    "        # Display the response\n",
    "        model_used = \"gpt-4\" if \"gpt-4\" in str(gpt_models) else \"gpt-3.5-turbo\"\n",
    "        print(f\"âœ… Financial Analysis from {model_used}:\\n\")\n",
    "        print(response.choices[0].message.content)\n",
    "        \n",
    "        # Display token usage\n",
    "        print(\"\\nðŸ“Š Token Usage:\")\n",
    "        print(f\"   Prompt tokens: {response.usage.prompt_tokens}\")\n",
    "        print(f\"   Completion tokens: {response.usage.completion_tokens}\")\n",
    "        print(f\"   Total tokens: {response.usage.total_tokens}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9563b03b",
   "metadata": {},
   "source": [
    "## 8. Connecting to DeepSeek API\n",
    "\n",
    "Now let's explore DeepSeek's models. DeepSeek is a newer provider that offers competitive LLMs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65125b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requests library if not already installed\n",
    "try:\n",
    "    import requests\n",
    "    print(f\"âœ… Requests library is installed\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ Requests library not found. Installing...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"requests\"])\n",
    "    import requests\n",
    "    print(f\"âœ… Requests library installed\")\n",
    "\n",
    "# Set up DeepSeek API\n",
    "if not check_api_key(deepseek_api_key, \"deepseek\"):\n",
    "    print(\"âš ï¸ Skipping DeepSeek examples due to missing API key\")\n",
    "else:\n",
    "    import json\n",
    "    import requests\n",
    "    \n",
    "    # Initialize headers and API base URL\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {deepseek_api_key}\"\n",
    "    }\n",
    "    \n",
    "    # Testing connection to DeepSeek API\n",
    "    try:\n",
    "        # Get available models (if API supports this endpoint)\n",
    "        # Note: Adjust this endpoint based on DeepSeek's actual API structure\n",
    "        models_url = f\"{deepseek_api_base}/models\"\n",
    "        models_response = requests.get(models_url, headers=headers)\n",
    "        \n",
    "        if models_response.status_code == 200:\n",
    "            models_data = models_response.json()\n",
    "            print(\"ðŸš€ DeepSeek API Connection Established\")\n",
    "            print(\"\\nðŸ“‹ Available Models:\")\n",
    "            for i, model in enumerate(models_data.get(\"data\", []), 1):\n",
    "                print(f\"   {i}. {model.get('id')}\")\n",
    "        else:\n",
    "            # If the models endpoint doesn't work, just confirm connection\n",
    "            print(\"ðŸš€ DeepSeek API Connection Established\")\n",
    "            print(\"â„¹ï¸ Models listing not available or requires different endpoint\")\n",
    "            print(\"   Will use default model for examples\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error connecting to DeepSeek API: {e}\")\n",
    "        print(\"   This could be due to an invalid API key or connection issue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340b1f2c",
   "metadata": {},
   "source": [
    "## 9. Text Generation with DeepSeek\n",
    "\n",
    "Let's try text generation with DeepSeek models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5157b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text generation with DeepSeek\n",
    "if not check_api_key(deepseek_api_key, \"deepseek\"):\n",
    "    print(\"âš ï¸ Skipping DeepSeek examples due to missing API key\")\n",
    "else:\n",
    "    # Define the same financial prompt for comparison\n",
    "    financial_prompt = \"Explain what an ETF is in simple terms and list three popular ones.\"\n",
    "    \n",
    "    print(\"ðŸ¤– Testing DeepSeek Text Generation\\n\")\n",
    "    print(f\"Prompt: {financial_prompt}\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Prepare the request\n",
    "        url = f\"{deepseek_api_base}/chat/completions\"\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": \"deepseek-chat\",  # Adjust based on available models\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a financial expert providing clear and concise information.\"},\n",
    "                {\"role\": \"user\", \"content\": financial_prompt}\n",
    "            ],\n",
    "            \"max_tokens\": 300,\n",
    "            \"temperature\": 0.7\n",
    "        }\n",
    "        \n",
    "        # Send the request\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            \n",
    "            # Display the response\n",
    "            print(\"âœ… Response from DeepSeek:\\n\")\n",
    "            print(result[\"choices\"][0][\"message\"][\"content\"])\n",
    "            \n",
    "            # Display token usage if available\n",
    "            if \"usage\" in result:\n",
    "                print(\"\\nðŸ“Š Token Usage:\")\n",
    "                print(f\"   Prompt tokens: {result['usage'].get('prompt_tokens', 'N/A')}\")\n",
    "                print(f\"   Completion tokens: {result['usage'].get('completion_tokens', 'N/A')}\")\n",
    "                print(f\"   Total tokens: {result['usage'].get('total_tokens', 'N/A')}\")\n",
    "        else:\n",
    "            print(f\"âŒ Error: {response.status_code}\")\n",
    "            print(response.text)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49e59de",
   "metadata": {},
   "source": [
    "## 10. Financial Scenario Analysis with DeepSeek\n",
    "\n",
    "Let's try another financial analysis task with DeepSeek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e40119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Financial scenario analysis with DeepSeek\n",
    "if not check_api_key(deepseek_api_key, \"deepseek\"):\n",
    "    print(\"âš ï¸ Skipping DeepSeek examples due to missing API key\")\n",
    "else:\n",
    "    # Financial scenario prompt\n",
    "    scenario_prompt = \"\"\"\n",
    "    As a financial advisor, analyze the impact of the following macroeconomic scenario:\n",
    "    \n",
    "    - Federal Reserve raises interest rates by 75 basis points\n",
    "    - Inflation has decreased from 6.5% to 4.8% YoY\n",
    "    - Unemployment remains steady at 3.7%\n",
    "    - Housing market shows signs of cooling with prices down 3% MoM\n",
    "    \n",
    "    What investment strategy would you recommend for:\n",
    "    1. A conservative retiree with a $1M portfolio\n",
    "    2. An aggressive young investor with a 30-year time horizon\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ðŸ“ˆ Financial Scenario Analysis Example\\n\")\n",
    "    print(\"Prompt: Analyzing impact of Fed rate hikes and inflation...\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Prepare the request\n",
    "        url = f\"{deepseek_api_base}/chat/completions\"\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": \"deepseek-chat\",  # Adjust based on available models\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are an experienced financial advisor who provides balanced, thoughtful investment recommendations based on macroeconomic conditions.\"},\n",
    "                {\"role\": \"user\", \"content\": scenario_prompt}\n",
    "            ],\n",
    "            \"max_tokens\": 800,\n",
    "            \"temperature\": 0.5  # Lower for more focused analysis\n",
    "        }\n",
    "        \n",
    "        # Send the request\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            \n",
    "            # Display the response\n",
    "            print(\"âœ… Financial Analysis from DeepSeek:\\n\")\n",
    "            print(result[\"choices\"][0][\"message\"][\"content\"])\n",
    "            \n",
    "            # Display token usage if available\n",
    "            if \"usage\" in result:\n",
    "                print(\"\\nðŸ“Š Token Usage:\")\n",
    "                print(f\"   Prompt tokens: {result['usage'].get('prompt_tokens', 'N/A')}\")\n",
    "                print(f\"   Completion tokens: {result['usage'].get('completion_tokens', 'N/A')}\")\n",
    "                print(f\"   Total tokens: {result['usage'].get('total_tokens', 'N/A')}\")\n",
    "        else:\n",
    "            print(f\"âŒ Error: {response.status_code}\")\n",
    "            print(response.text)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168ff7c1",
   "metadata": {},
   "source": [
    "## 11. Comparing OpenAI and DeepSeek\n",
    "\n",
    "Let's directly compare responses from both providers on the same prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128f8e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing OpenAI and DeepSeek\n",
    "comparison_prompt = \"\"\"\n",
    "Perform a SWOT analysis (Strengths, Weaknesses, Opportunities, Threats) for a FinTech startup \n",
    "that is developing a new AI-powered robo-advisor for sustainable investing.\n",
    "Provide 3-4 bullet points for each SWOT category.\n",
    "\"\"\"\n",
    "\n",
    "print(\"âš–ï¸ Comparing OpenAI vs DeepSeek\\n\")\n",
    "print(f\"Prompt: {comparison_prompt.strip()}\\n\")\n",
    "\n",
    "# OpenAI response\n",
    "if check_api_key(openai_api_key, \"openai\"):\n",
    "    try:\n",
    "        # Create a completion\n",
    "        openai_response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a strategic business consultant with expertise in FinTech.\"},\n",
    "                {\"role\": \"user\", \"content\": comparison_prompt}\n",
    "            ],\n",
    "            max_tokens=800,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        # Store the response\n",
    "        openai_result = openai_response.choices[0].message.content\n",
    "        openai_tokens = openai_response.usage.total_tokens\n",
    "        \n",
    "        print(\"âœ… OpenAI Response:\")\n",
    "        print(openai_result)\n",
    "        print(f\"\\nTokens used: {openai_tokens}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ OpenAI Error: {e}\")\n",
    "        openai_result = None\n",
    "else:\n",
    "    print(\"âš ï¸ Skipping OpenAI due to missing API key\")\n",
    "    openai_result = None\n",
    "\n",
    "print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "\n",
    "# DeepSeek response\n",
    "if check_api_key(deepseek_api_key, \"deepseek\"):\n",
    "    try:\n",
    "        # Prepare the request\n",
    "        url = f\"{deepseek_api_base}/chat/completions\"\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": \"deepseek-chat\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a strategic business consultant with expertise in FinTech.\"},\n",
    "                {\"role\": \"user\", \"content\": comparison_prompt}\n",
    "            ],\n",
    "            \"max_tokens\": 800,\n",
    "            \"temperature\": 0.7\n",
    "        }\n",
    "        \n",
    "        # Send the request\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            \n",
    "            # Store the response\n",
    "            deepseek_result = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "            deepseek_tokens = result.get(\"usage\", {}).get(\"total_tokens\", \"N/A\")\n",
    "            \n",
    "            print(\"âœ… DeepSeek Response:\")\n",
    "            print(deepseek_result)\n",
    "            print(f\"\\nTokens used: {deepseek_tokens}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"âŒ DeepSeek Error: {response.status_code}\")\n",
    "            print(response.text)\n",
    "            deepseek_result = None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ DeepSeek Error: {e}\")\n",
    "        deepseek_result = None\n",
    "else:\n",
    "    print(\"âš ï¸ Skipping DeepSeek due to missing API key\")\n",
    "    deepseek_result = None\n",
    "\n",
    "# Simple comparison if both results are available\n",
    "if openai_result and deepseek_result:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸ“Š Comparison Summary:\")\n",
    "    \n",
    "    # Length comparison\n",
    "    openai_length = len(openai_result.split())\n",
    "    deepseek_length = len(deepseek_result.split())\n",
    "    \n",
    "    print(f\"\\nResponse Length (words):\")\n",
    "    print(f\"   OpenAI: {openai_length}\")\n",
    "    print(f\"   DeepSeek: {deepseek_length}\")\n",
    "    \n",
    "    # Basic overlap analysis (very simple)\n",
    "    openai_words = set(w.lower() for w in openai_result.split() if len(w) > 5)\n",
    "    deepseek_words = set(w.lower() for w in deepseek_result.split() if len(w) > 5)\n",
    "    common_words = openai_words.intersection(deepseek_words)\n",
    "    \n",
    "    overlap_percent = len(common_words) / len(openai_words.union(deepseek_words)) * 100\n",
    "    \n",
    "    print(f\"\\nContent Similarity:\")\n",
    "    print(f\"   Vocabulary overlap: {overlap_percent:.1f}%\")\n",
    "    print(f\"   Common significant terms: {', '.join(list(common_words)[:10])}\" + (\"...\" if len(common_words) > 10 else \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96125296",
   "metadata": {},
   "source": [
    "## 12. Best Practices for API Usage\n",
    "\n",
    "Let's summarize some best practices for working with LLM APIs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024e3cee",
   "metadata": {},
   "source": [
    "### API Key Management\n",
    "\n",
    "1. **Store API Keys in .env Files**\n",
    "   - Create a `.env` file for your API keys\n",
    "   - Add `.env` to your `.gitignore`\n",
    "   - Use `python-dotenv` to load the variables\n",
    "\n",
    "2. **Version Control Safety**\n",
    "   - Provide a `.env.example` template (without real keys)\n",
    "   - Commit `.env.example` to your repository\n",
    "   - NEVER commit the real `.env` file\n",
    "\n",
    "3. **Key Rotation and Security**\n",
    "   - Regularly rotate your API keys (especially in production)\n",
    "   - Set usage limits on your API keys\n",
    "   - Use different keys for development and production\n",
    "\n",
    "### Cost Management\n",
    "\n",
    "1. **Monitor API Usage**\n",
    "   - Track token usage for each request\n",
    "   - Set budget alerts and limits\n",
    "   - Use smaller models when possible\n",
    "\n",
    "2. **Optimize Prompts**\n",
    "   - Keep prompts concise but clear\n",
    "   - Use system messages to set context\n",
    "   - Adjust `max_tokens` based on your needs\n",
    "\n",
    "3. **Caching**\n",
    "   - Cache responses for identical requests\n",
    "   - Implement TTL (Time-To-Live) for cached responses\n",
    "   - Consider semantic caching for similar requests\n",
    "\n",
    "### Error Handling\n",
    "\n",
    "1. **Robust Error Handling**\n",
    "   - Handle rate limits with exponential backoff\n",
    "   - Implement fallbacks between models/providers\n",
    "   - Log errors for debugging\n",
    "\n",
    "2. **Validation**\n",
    "   - Validate inputs before sending to API\n",
    "   - Validate outputs for expected format\n",
    "   - Implement content filtering where needed\n",
    "\n",
    "### Advanced Usage\n",
    "\n",
    "1. **Function Calling**\n",
    "   - Use function calling for structured outputs\n",
    "   - Define clear JSON schemas\n",
    "   - Validate returned JSON\n",
    "\n",
    "2. **Streaming**\n",
    "   - Use streaming for better UX on longer responses\n",
    "   - Process chunks as they arrive\n",
    "   - Implement early stopping if needed\n",
    "\n",
    "3. **RAG (Retrieval-Augmented Generation)**\n",
    "   - Combine APIs with your own data sources\n",
    "   - Use embeddings for semantic search\n",
    "   - Implement proper citation and attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f83d80d",
   "metadata": {},
   "source": [
    "## 13. Project: Financial News Sentiment Analyzer\n",
    "\n",
    "Let's build a simple but practical example: a financial news sentiment analyzer using the OpenAI or DeepSeek API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095caeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Financial News Sentiment Analyzer\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Check if we have at least one API key available\n",
    "have_api = check_api_key(openai_api_key, \"openai\") or check_api_key(deepseek_api_key, \"deepseek\")\n",
    "\n",
    "if not have_api:\n",
    "    print(\"âš ï¸ No valid API keys found. Please add at least one API key to your .env file.\")\n",
    "else:\n",
    "    print(\"ðŸ” Financial News Sentiment Analyzer\\n\")\n",
    "    \n",
    "    # Sample financial news headlines\n",
    "    financial_news = [\n",
    "        {\"date\": \"2025-06-01\", \"headline\": \"Tesla reports record quarterly deliveries, shares jump 8%\"},\n",
    "        {\"date\": \"2025-06-02\", \"headline\": \"Fed signals potential interest rate cut in September\"},\n",
    "        {\"date\": \"2025-06-03\", \"headline\": \"Amazon acquires AI startup for $2.5 billion\"},\n",
    "        {\"date\": \"2025-06-04\", \"headline\": \"Inflation rises to 5.2%, exceeding economist expectations\"},\n",
    "        {\"date\": \"2025-06-05\", \"headline\": \"Tech stocks tumble amid renewed regulatory concerns\"},\n",
    "        {\"date\": \"2025-06-06\", \"headline\": \"Bitcoin surpasses $100,000 for the first time\"},\n",
    "        {\"date\": \"2025-06-07\", \"headline\": \"Major bank announces 5,000 layoffs amid restructuring\"},\n",
    "        {\"date\": \"2025-06-08\", \"headline\": \"Apple unveils new product line at annual conference\"},\n",
    "        {\"date\": \"2025-06-09\", \"headline\": \"Oil prices drop 10% as OPEC increases production\"},\n",
    "        {\"date\": \"2025-06-10\", \"headline\": \"Consumer confidence index hits 5-year high\"}\n",
    "    ]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    news_df = pd.DataFrame(financial_news)\n",
    "    print(f\"ðŸ“° Analyzing {len(news_df)} financial news headlines...\\n\")\n",
    "    \n",
    "    # Function to analyze sentiment with OpenAI\n",
    "    def analyze_with_openai(headline):\n",
    "        if not check_api_key(openai_api_key, \"openai\"):\n",
    "            return {\"sentiment\": \"N/A\", \"score\": 0, \"rationale\": \"API key not available\"}\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a financial analyst. Analyze the sentiment of financial news headlines.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"\"\"Analyze the sentiment of this financial news headline:\n",
    "                    \n",
    "                    \"{headline}\"\n",
    "                    \n",
    "                    Provide your response in JSON format with the following fields:\n",
    "                    - sentiment: Either \"positive\", \"negative\", or \"neutral\"\n",
    "                    - score: A number from -1.0 (very negative) to 1.0 (very positive)\n",
    "                    - rationale: A brief explanation of your reasoning (max 20 words)\"\"\"}\n",
    "                ],\n",
    "                max_tokens=150,\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            # Extract the JSON response\n",
    "            content = response.choices[0].message.content\n",
    "            # Use regex to extract JSON\n",
    "            json_match = re.search(r'\\{[^}]+\\}', content.replace('\\n', ' '))\n",
    "            if json_match:\n",
    "                import json\n",
    "                result = json.loads(json_match.group(0))\n",
    "            else:\n",
    "                # Fallback parsing for non-JSON responses\n",
    "                if \"positive\" in content.lower():\n",
    "                    sentiment = \"positive\"\n",
    "                    score = 0.7\n",
    "                elif \"negative\" in content.lower():\n",
    "                    sentiment = \"negative\"\n",
    "                    score = -0.7\n",
    "                else:\n",
    "                    sentiment = \"neutral\"\n",
    "                    score = 0\n",
    "                result = {\n",
    "                    \"sentiment\": sentiment,\n",
    "                    \"score\": score,\n",
    "                    \"rationale\": content[:50] + \"...\"\n",
    "                }\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing '{headline}': {e}\")\n",
    "            return {\"sentiment\": \"error\", \"score\": 0, \"rationale\": str(e)[:50]}\n",
    "    \n",
    "    # Function to analyze sentiment with DeepSeek\n",
    "    def analyze_with_deepseek(headline):\n",
    "        if not check_api_key(deepseek_api_key, \"deepseek\"):\n",
    "            return {\"sentiment\": \"N/A\", \"score\": 0, \"rationale\": \"API key not available\"}\n",
    "        \n",
    "        try:\n",
    "            url = f\"{deepseek_api_base}/chat/completions\"\n",
    "            \n",
    "            payload = {\n",
    "                \"model\": \"deepseek-chat\",\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"You are a financial analyst. Analyze the sentiment of financial news headlines.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"\"\"Analyze the sentiment of this financial news headline:\n",
    "                    \n",
    "                    \"{headline}\"\n",
    "                    \n",
    "                    Provide your response in JSON format with the following fields:\n",
    "                    - sentiment: Either \"positive\", \"negative\", or \"neutral\"\n",
    "                    - score: A number from -1.0 (very negative) to 1.0 (very positive)\n",
    "                    - rationale: A brief explanation of your reasoning (max 20 words)\"\"\"}\n",
    "                ],\n",
    "                \"max_tokens\": 150,\n",
    "                \"temperature\": 0.3\n",
    "            }\n",
    "            \n",
    "            response = requests.post(url, headers=headers, json=payload)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                content = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "                \n",
    "                # Use regex to extract JSON\n",
    "                json_match = re.search(r'\\{[^}]+\\}', content.replace('\\n', ' '))\n",
    "                if json_match:\n",
    "                    import json\n",
    "                    result = json.loads(json_match.group(0))\n",
    "                else:\n",
    "                    # Fallback parsing for non-JSON responses\n",
    "                    if \"positive\" in content.lower():\n",
    "                        sentiment = \"positive\"\n",
    "                        score = 0.7\n",
    "                    elif \"negative\" in content.lower():\n",
    "                        sentiment = \"negative\"\n",
    "                        score = -0.7\n",
    "                    else:\n",
    "                        sentiment = \"neutral\"\n",
    "                        score = 0\n",
    "                    result = {\n",
    "                        \"sentiment\": sentiment,\n",
    "                        \"score\": score,\n",
    "                        \"rationale\": content[:50] + \"...\"\n",
    "                    }\n",
    "                \n",
    "                return result\n",
    "            else:\n",
    "                return {\"sentiment\": \"error\", \"score\": 0, \"rationale\": f\"API error: {response.status_code}\"}\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing '{headline}': {e}\")\n",
    "            return {\"sentiment\": \"error\", \"score\": 0, \"rationale\": str(e)[:50]}\n",
    "    \n",
    "    # Choose which API to use based on available keys\n",
    "    if check_api_key(openai_api_key, \"openai\"):\n",
    "        analyze_sentiment = analyze_with_openai\n",
    "        api_used = \"OpenAI\"\n",
    "    elif check_api_key(deepseek_api_key, \"deepseek\"):\n",
    "        analyze_sentiment = analyze_with_deepseek\n",
    "        api_used = \"DeepSeek\"\n",
    "    else:\n",
    "        print(\"âš ï¸ No valid API keys found. Cannot proceed with analysis.\")\n",
    "        analyze_sentiment = None\n",
    "        api_used = None\n",
    "    \n",
    "    # Process headlines if we have a valid API\n",
    "    if analyze_sentiment:\n",
    "        results = []\n",
    "        \n",
    "        print(f\"ðŸ”„ Processing with {api_used} API...\")\n",
    "        for i, row in news_df.iterrows():\n",
    "            print(f\"   Analyzing ({i+1}/{len(news_df)}): {row['headline'][:40]}...\")\n",
    "            result = analyze_sentiment(row['headline'])\n",
    "            \n",
    "            # Add result to our data\n",
    "            results.append({\n",
    "                \"date\": row['date'],\n",
    "                \"headline\": row['headline'],\n",
    "                \"sentiment\": result.get(\"sentiment\", \"N/A\"),\n",
    "                \"score\": result.get(\"score\", 0),\n",
    "                \"rationale\": result.get(\"rationale\", \"N/A\")\n",
    "            })\n",
    "            \n",
    "            # Sleep briefly to avoid rate limits\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        # Create results DataFrame\n",
    "        results_df = pd.DataFrame(results)\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\nðŸ“Š Sentiment Analysis Results:\\n\")\n",
    "        for i, row in results_df.iterrows():\n",
    "            # Create an emoji indicator\n",
    "            if row['sentiment'] == \"positive\":\n",
    "                emoji = \"ðŸ“ˆ\"\n",
    "                color = \"\\033[92m\"  # Green\n",
    "            elif row['sentiment'] == \"negative\":\n",
    "                emoji = \"ðŸ“‰\"\n",
    "                color = \"\\033[91m\"  # Red\n",
    "            else:\n",
    "                emoji = \"âž¡ï¸\"\n",
    "                color = \"\\033[93m\"  # Yellow\n",
    "            \n",
    "            # Reset color\n",
    "            reset = \"\\033[0m\"\n",
    "            \n",
    "            print(f\"{row['date']} | {color}{row['sentiment'].upper()} ({row['score']:+.2f}){reset} {emoji}\")\n",
    "            print(f\"   {row['headline']}\")\n",
    "            print(f\"   Rationale: {row['rationale']}\")\n",
    "            print(\"-\" * 80)\n",
    "        \n",
    "        # Create a visualization\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Convert date to datetime for proper sorting\n",
    "        results_df['date'] = pd.to_datetime(results_df['date'])\n",
    "        results_df = results_df.sort_values('date')\n",
    "        \n",
    "        # Plot 1: Sentiment score timeline\n",
    "        plt.subplot(2, 1, 1)\n",
    "        sns.lineplot(x='date', y='score', data=results_df, marker='o', linewidth=2)\n",
    "        plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
    "        plt.title(f'Financial News Sentiment Timeline ({api_used} Analysis)', fontsize=14)\n",
    "        plt.ylabel('Sentiment Score (-1 to +1)')\n",
    "        plt.ylim(-1.1, 1.1)\n",
    "        \n",
    "        # Annotate points with headlines (shortened)\n",
    "        for i, row in results_df.iterrows():\n",
    "            short_headline = row['headline'][:20] + \"...\" if len(row['headline']) > 20 else row['headline']\n",
    "            plt.annotate(short_headline, (row['date'], row['score']), \n",
    "                        xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "        \n",
    "        # Plot 2: Sentiment distribution\n",
    "        plt.subplot(2, 1, 2)\n",
    "        sentiment_counts = results_df['sentiment'].value_counts()\n",
    "        colors = {'positive': 'green', 'negative': 'red', 'neutral': 'orange', 'error': 'gray'}\n",
    "        sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, \n",
    "                   palette=[colors.get(x, 'blue') for x in sentiment_counts.index])\n",
    "        plt.title('Sentiment Distribution', fontsize=14)\n",
    "        plt.ylabel('Count')\n",
    "        plt.xlabel('Sentiment')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, v in enumerate(sentiment_counts.values):\n",
    "            plt.text(i, v + 0.1, str(v), ha='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('financial_news_sentiment.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # Save results to CSV\n",
    "        results_df.to_csv('financial_news_sentiment_results.csv', index=False)\n",
    "        print(\"\\nðŸ’¾ Results saved to 'financial_news_sentiment_results.csv'\")\n",
    "        print(\"ðŸ“Š Visualization saved to 'financial_news_sentiment.png'\")\n",
    "        \n",
    "        # Calculate market sentiment indicator\n",
    "        avg_sentiment = results_df['score'].mean()\n",
    "        sentiment_direction = \"BULLISH\" if avg_sentiment > 0.3 else \"BEARISH\" if avg_sentiment < -0.3 else \"NEUTRAL\"\n",
    "        \n",
    "        print(f\"\\nðŸ“ˆ Market Sentiment Indicator: {sentiment_direction}\")\n",
    "        print(f\"   Average Sentiment Score: {avg_sentiment:.2f}\")\n",
    "        \n",
    "        # Most positive and negative headlines\n",
    "        if len(results_df) > 0:\n",
    "            most_positive = results_df.loc[results_df['score'].idxmax()]\n",
    "            most_negative = results_df.loc[results_df['score'].idxmin()]\n",
    "            \n",
    "            print(f\"\\nðŸ“° Most Positive News: {most_positive['headline']}\")\n",
    "            print(f\"   Score: +{most_positive['score']:.2f}\")\n",
    "            \n",
    "            print(f\"\\nðŸ“° Most Negative News: {most_negative['headline']}\")\n",
    "            print(f\"   Score: {most_negative['score']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe01e053",
   "metadata": {},
   "source": [
    "## 14. Summary and Next Steps\n",
    "\n",
    "### What We've Learned\n",
    "- How to securely manage API keys using `.env` files\n",
    "- How to properly exclude sensitive files with `.gitignore`\n",
    "- How to connect to and use OpenAI's API\n",
    "- How to connect to and use DeepSeek's API\n",
    "- How to compare responses from different providers\n",
    "- How to build a practical financial news sentiment analyzer\n",
    "\n",
    "### Best Practices Recap\n",
    "- Never hardcode API keys in your code\n",
    "- Always use environment variables\n",
    "- Add `.env` to your `.gitignore`\n",
    "- Create `.env.example` templates for collaboration\n",
    "- Implement robust error handling\n",
    "- Monitor and manage API usage costs\n",
    "\n",
    "### Next Steps\n",
    "1. **Explore More Models**: Try different models from each provider\n",
    "2. **Build Financial Applications**: Create more sophisticated financial tools\n",
    "3. **Implement RAG**: Combine LLMs with your own financial data\n",
    "4. **Fine-tune Models**: Train models on financial domain data\n",
    "5. **Deploy Applications**: Create user interfaces for your LLM applications\n",
    "\n",
    "### Additional Resources\n",
    "- [OpenAI API Documentation](https://platform.openai.com/docs/api-reference)\n",
    "- [DeepSeek API Documentation](https://platform.deepseek.com/)\n",
    "- [LangChain Library](https://python.langchain.com/) - For building more complex LLM applications\n",
    "- [LlamaIndex](https://docs.llamaindex.ai/) - For connecting LLMs to your custom data\n",
    "- [API Security Best Practices](https://owasp.org/www-project-api-security/)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
