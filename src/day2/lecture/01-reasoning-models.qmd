# Reasoning Models: Beyond Next Token Prediction

## From Token Generation to Reasoning Chains

- **Traditional LLM prediction**:
  - Single forward pass: $P(x_{t+1} | x_1, x_2, ..., x_t)$
  - Direct mapping from context to next token
  - Temperature controls randomness in sampling
  - No explicit intermediate reasoning steps
  
- **Reasoning models approach**:
  - Multi-step generation: $P(goal | reasoning\_chain)$
  - Explicit intermediate thought tokens
  - Chain-of-thought: $P(answer | context, thoughts)$
  - Goal-oriented sequence generation

- **Mathematical distinction**:
  
  **Standard generation**:
  $$P(x_{t+1}) = \text{softmax}(W_o h_t)$$
  
  **Reasoning generation**:
  $$P(answer) = \prod_{i=1}^{n} P(t_i | c, t_{1:i-1}) \times P(a | c, t_{1:n})$$
  
  Where:
  - $t_i$ = thought/reasoning step $i$
  - $c$ = context
  - $a$ = final answer
  - $n$ = number of reasoning steps
  
- **Key difference**: Intermediate reasoning states influence final outcome

## Mathematical Framework of Reasoning Models

- **Standard next-token prediction**:
  $$P(x_{t+1} | x_{1:t}) = \frac{e^{z_{t+1}}}{\sum_{v \in V} e^{z_v}}$$
  
  Where:
  - $z_{t+1} = W_o h_t + b_o$ = logits for next token
  - $V$ = vocabulary
  - $h_t$ = hidden state at position $t$
  
- **Reasoning chain generation**:
  $$P(R) = \prod_{i=1}^{n} P(r_i | c, r_{1:i-1})$$
  
  $$P(A | R) = P(a | c, r_{1:n})$$
  
  Where:
  - $R$ = reasoning chain
  - $r_i$ = reasoning step $i$
  - $A$ = final answer

::: {.column width="40%"}
- **Temperature in reasoning context**:
  
  **Standard softmax with temperature**:
  $$P(x_i) = \frac{e^{z_i/T}}{\sum_{j} e^{z_j/T}}$$
  
  **Reasoning requires $T > 0$ because**:
  - Need exploration of reasoning paths
  - Multiple valid intermediate steps
  - Diversity in thought processes
  - Avoiding reasoning dead-ends
:::

::::

## Why Temperature Cannot Be Zero in Reasoning

:::: {.columns}

::: {.column width="60%"}
- **Mathematical constraint**: $T \to 0$ leads to deterministic selection
  $$\lim_{T \to 0} P(x_i) = \begin{cases} 
  1 & \text{if } i = \arg\max_j z_j \\
  0 & \text{otherwise}
  \end{cases}$$
  
- **Problem with deterministic reasoning**:
  - Only one reasoning path explored
  - No recovery from sub-optimal intermediate steps
  - Reasoning becomes brittle and inflexible
  - Cannot explore alternative valid approaches
:::

::: {.column width="40%"}
- **Reasoning examples**:
  
  **Problem**: Solve a complex multi-step problem
  
  **With $T = 0$ (deterministic)**:
  - Always chooses same first reasoning step
  - Cannot explore alternative approaches
  - Gets stuck if initial assumption is suboptimal
  
  **With $T > 0$ (stochastic)**:
  - Can explore multiple solution methods
  - Considers different assumptions
  - Allows for uncertainty quantification
:::

::::

## Reasoning Chain Decomposition

:::: {.columns}

::: {.column width="60%"}
- **Multi-step probability factorization**:
  $$P(A | Q) = \sum_{R} P(A | R) \times P(R | Q)$$
  
  Where:
  - $A$ = answer
  - $Q$ = question  
  - $R$ = reasoning path
  
- **Each reasoning step**:
  $$P(r_i | c, r_{1:i-1}) = \text{softmax}\left(\frac{f_\theta(c, r_{1:i-1})}{T}\right)$$
  
  Where:
  - $r_i$ = reasoning step $i$
  - $c$ = context
  - $T$ = temperature
  
- **Final answer conditioning**:
  $$P(A | R) = \text{softmax}\left(\frac{g_\theta(R)}{T_f}\right)$$
  
  Where $T_f$ = final temperature
:::

::: {.column width="40%"}
- **Temperature effects across reasoning**:
  
  **High temperature ($T > 1$)**:
  - More diverse reasoning paths
  - Higher creativity in problem-solving
  - Risk of incoherent reasoning
  
  **Moderate temperature ($0.3 < T < 1$)**:
  - Balanced exploration vs. exploitation
  - Coherent but diverse reasoning
  - Optimal for most complex problems
  
  **Low temperature ($T \to 0$)**:
  - Deterministic, rigid reasoning
  - Cannot recover from mistakes
  - Limited problem-solving capability
:::

::::
## Information Theory of Reasoning

- **Entropy in reasoning steps**:
  $$H(R_i) = -\sum_{r_i} P(r_i \mid \text{context},\, r_{1:i-1}) \log P(r_i \mid \text{context},\, r_{1:i-1})$$
  
- **Total reasoning entropy**:
  $$H(\text{Reasoning}) = \sum_{i=1}^{n} H(R_i \mid R_{1:i-1})$$
  
- **Conditional mutual information**:
  $$I(A;\, R \mid Q) = H(A \mid Q) - H(A \mid Q,\, R)$$
  
  Where:
  - $A$ = Answer
  - $R$ = Reasoning Path
  - $Q$ = Question
  - $I(A;\, R \mid Q)$ = Mutual information between Answer and Reasoning Path given Question
  - $H(A \mid Q)$ = Entropy of Answer given Question
  - $H(A \mid Q,\, R)$ = Entropy of Answer given Question and Reasoning Path
  
- **Why entropy matters in reasoning**:
  - Zero entropy ($T = 0$): $H(R_i) = 0$ for all reasoning steps â€” deterministic, no exploration, cannot adapt to new information
  - Positive entropy ($T > 0$): $H(R_i) > 0$ allows exploration, can discover optimal reasoning paths, adapts to intermediate findings
  - General implications: complex analysis requires uncertainty handling; multiple valid analytical approaches; need to explore scenario variations
::::

## Reasoning vs. Direct Prediction: Mathematical Comparison

- **Direct prediction complexity**:
  $$P(answer \mid question) = \text{softmax}(W_o h_{final})$$
  
  Single forward pass, $O(|V|)$ complexity for final softmax
  
- **Reasoning model complexity**:
  $$P(answer \mid question) = \sum_{paths} \prod_{i=1}^{n} P(r_i \mid context, r_{1:i-1}) \times P(answer \mid reasoning)$$
  
  Multiple forward passes, $O(n \times |V|)$ complexity
  
- **Computational trade-offs**:
  
  **Direct prediction**:
  - Fast inference: $O(1)$ forward pass
  - Limited reasoning capability
  - Suitable for simple tasks
  
  **Reasoning models**:
  - Slower inference: $O(n)$ forward passes
  - Enhanced problem-solving
  - Required for complex analytical tasks
  
- **Quality vs. efficiency trade-off**:
  - Reasoning models: higher accuracy, slower
  - Direct models: faster, limited capability

## Temperature Scheduling in Reasoning

:::: {.columns}

::: {.column width="60%"}
- **Adaptive temperature across reasoning steps**:
  $$T_i = T_0 \times \text{schedule}(i, context, partial\_reasoning)$$
  
- **Common scheduling strategies**:
  
  **Linear decay**: $T_i = T_0 \times (1 - \frac{i}{n})$
  
  **Exponential decay**: $T_i = T_0 \times e^{-\lambda i}$
  
  **Content-aware**: $T_i = f(confidence, complexity, stakes)$
:::

::: {.column width="40%"}
- **Temperature strategies for different task types**:
  
  **High-precision tasks** (mathematical computation):
  - Start with $T_0 = 0.3$ (conservative)
  - Decay to $T_{final} = 0.1$ (precise)
  
  **Exploratory analysis** (research, brainstorming):
  - Start with $T_0 = 0.8$ (creative)
  - Maintain $T > 0.5$ throughout
  
  **Mixed reasoning tasks**:
  - Variable temperature based on step type
  - Lower $T$ for computational steps
  - Higher $T$ for interpretation steps
:::

::::

## Reasoning Path Optimization

:::: {.columns}

::: {.column width="60%"}
- **Beam search in reasoning space**:
  Keep top-$k$ reasoning paths at each step
  
  $$\text{Score}(path) = \frac{1}{|path|} \sum_{i=1}^{|path|} \log P(r_i | context, r_{1:i-1})$$
  
- **Path pruning criteria**:
  - Coherence score below threshold
  - Logical inconsistency detection
  - Factual accuracy verification
  - Domain-specific validity checks
:::

::: {.column width="40%"}
- **Multi-path reasoning benefits**:
  
  **Robustness**:
  - Multiple valid approaches to same problem
  - Cross-validation of reasoning steps
  - Error detection through inconsistency
  
  **Uncertainty quantification**:
  - Confidence from path agreement
  - Range estimation from path diversity
  - Risk assessment from reasoning variance
  
- **Example**: Multi-step problem solving
  - Path 1: Conservative assumptions
  - Path 2: Optimistic conditions
  - Path 3: Stress-test scenarios
:::

::::

## Self-Consistency and Verification

:::: {.columns}

::: {.column width="60%"}
- **Self-consistency scoring**:
  Generate $m$ reasoning paths, measure agreement
  
  $$\text{Consistency} = \frac{1}{m(m-1)} \sum_{i \neq j} \text{similarity}(answer_i, answer_j)$$
  
- **Reasoning verification**:
  $$P(correct | reasoning) = \sigma(W_v \cdot h_r)$$
  
  Where:
  - $W_v$ = verification network weights
  - $h_r$ = reasoning embedding
  - $\sigma$ = sigmoid function
:::

::: {.column width="40%"}
- **Why temperature enables verification**:
  
  **With $T > 0$**:
  - Generate diverse reasoning samples
  - Check consistency across approaches
  - Identify robust vs. fragile conclusions
  
  **With $T = 0$**:
  - Only one reasoning path
  - No verification possible
  - Cannot assess answer reliability
  
- **Verification example**:
  - Multiple solution approaches
  - Cross-check with alternative methods
  - Sensitivity analysis across scenarios
:::

::::

## Reasoning Model Architectures

- **Chain-of-Thought (CoT)**:
  $$P(answer \mid question) = P(answer \mid question, thoughts) \times P(thoughts \mid question)$$
  - Linear reasoning progression, simple to implement and understand, good for sequential analytical tasks

- **Tree-of-Thoughts (ToT)**:
  $$P(answer \mid question) = \max_{tree} \left( P(answer \mid question, tree) \times P(tree \mid question) \right)$$
  - Branching reasoning exploration, better for scenario analysis, higher computational cost

- **Graph-of-Thoughts (GoT)**:
  $$P(answer \mid question) = \sum_{graph} P(answer \mid question, graph) \times P(graph \mid question)$$
  - Complex relationship modeling, best for interconnected systems, highest computational complexity

## Generic Applications of Reasoning Models

:::: {.columns}

::: {.column width="60%"}
- **Mathematical problem solving**:
  1. Problem decomposition and analysis
  2. Method selection and justification
  3. Step-by-step solution development
  4. Result verification and validation
  5. Alternative approach exploration
  
- **Complex decision making**:
  1. Information gathering and analysis
  2. Criteria identification and weighting
  3. Option evaluation and comparison
  4. Trade-off analysis and reasoning
  5. Final decision justification
:::

::: {.column width="40%"}
- **Mathematical requirements**:
  
  **Each reasoning step needs $T > 0$**:
  - Explore alternative analytical approaches
  - Consider multiple scenario outcomes
  - Adapt to intermediate findings
  - Maintain reasoning flexibility
  
  **Example temperature settings**:
  - Mathematical computation: $T = 0.4$
  - Creative problem solving: $T = 0.7$
  - Logical analysis: $T = 0.3$
  - Hypothesis generation: $T = 0.6$
:::

::::

## Limitations and Future Directions

:::: {.columns}

::: {.column width="60%"}
- **Current limitations**:
  - Reasoning length constraints
  - Computational cost scaling
  - Quality assessment challenges
  - Integration with external knowledge
  
- **Mathematical challenges**:
  - Optimizing temperature schedules
  - Balancing exploration vs. exploitation
  - Measuring reasoning quality objectively
  - Handling reasoning contradictions
:::

::: {.column width="40%"}
- **Future research directions**:
  
  **Adaptive reasoning**:
  - Dynamic reasoning length
  - Context-aware temperature setting
  - Real-time quality assessment
  
  **Hybrid approaches**:
  - Reasoning + retrieval integration
  - Multi-modal reasoning incorporation
  - External tool usage in reasoning
  
  **Domain-specific developments**:
  - Domain-constrained reasoning
  - Quality assurance verification
  - Context-aware reasoning temperature
:::

::::

## Practical Implementation Considerations

:::: {.columns}

::: {.column width="60%"}
- **Temperature selection guidelines**:
  
  **High-precision tasks**: $T \in [0.1, 0.4]$
  - Mathematical computation
  - Logical verification
  - Rule-based reasoning
  
  **Analytical tasks**: $T \in [0.4, 0.7]$
  - Problem decomposition
  - Method selection
  - Strategy development
  
  **Creative tasks**: $T \in [0.7, 1.0]$
  - Hypothesis generation
  - Alternative exploration
  - Innovation brainstorming
:::

::: {.column width="40%"}
- **Quality control mechanisms**:
  
  **Reasoning validation**:
  - Logical consistency checking
  - Factual accuracy verification
  - Domain knowledge compliance
  - Mathematical correctness validation
  
  **Temperature optimization**:
  - A/B testing different temperature ranges
  - Performance monitoring across tasks
  - Expert evaluation of reasoning quality
  - Automated reasoning assessment metrics
  
- **Production considerations**:
  - Latency vs. quality trade-offs
  - Caching common reasoning patterns
  - Fallback to simpler models when needed
:::

::::
