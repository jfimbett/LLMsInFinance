{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1c288f4",
   "metadata": {},
   "source": [
    "# Python Crash Course for AI and Finance\n",
    "\n",
    "Welcome to this crash course on Python for AI applications in finance! This notebook covers the essentials you need to get started with Python, NumPy, and PyTorch, with a special focus on vectors and tensors used in neural networks and LLMs.\n",
    "\n",
    "## What We'll Cover\n",
    "\n",
    "1. Python Basics\n",
    "   - Variables and data types\n",
    "   - Control flow (conditionals and loops)\n",
    "   - Functions and modules\n",
    "\n",
    "2. NumPy Fundamentals\n",
    "   - Creating and manipulating arrays\n",
    "   - Vectorized operations\n",
    "   - Linear algebra basics\n",
    "\n",
    "3. PyTorch Introduction\n",
    "   - Tensors and operations\n",
    "   - Computing gradients\n",
    "   - Building basic neural network components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2503f67",
   "metadata": {},
   "source": [
    "## 1. Python Basics\n",
    "\n",
    "### Variables and Data Types\n",
    "\n",
    "Python is a dynamically typed language, which means you don't need to declare the type of a variable when you create one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9e73ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic variable assignments\n",
    "integer_value = 42\n",
    "float_value = 3.14159\n",
    "string_value = \"Hello, Finance!\"\n",
    "boolean_value = True\n",
    "\n",
    "# Print the variables and their types\n",
    "print(f\"Integer: {integer_value} (Type: {type(integer_value)})\")\n",
    "print(f\"Float: {float_value} (Type: {type(float_value)})\")\n",
    "print(f\"String: {string_value} (Type: {type(string_value)})\")\n",
    "print(f\"Boolean: {boolean_value} (Type: {type(boolean_value)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361d7998",
   "metadata": {},
   "source": [
    "### Financial Example: Stock Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8015c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Financial variables\n",
    "stock_ticker = \"AAPL\"\n",
    "current_price = 195.42\n",
    "shares_owned = 100\n",
    "is_in_portfolio = True\n",
    "\n",
    "# Calculate total value\n",
    "total_value = current_price * shares_owned\n",
    "\n",
    "print(f\"Stock: {stock_ticker}\")\n",
    "print(f\"Current Price: ${current_price}\")\n",
    "print(f\"Shares Owned: {shares_owned}\")\n",
    "print(f\"In Portfolio: {is_in_portfolio}\")\n",
    "print(f\"Total Value: ${total_value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3709eeb5",
   "metadata": {},
   "source": [
    "### Data Structures\n",
    "\n",
    "Python has several built-in data structures that are essential for data manipulation:\n",
    "\n",
    "1. **Lists**: Ordered, mutable collections of items\n",
    "2. **Dictionaries**: Key-value pairs for fast lookups\n",
    "3. **Tuples**: Immutable ordered collections\n",
    "4. **Sets**: Unordered collections of unique items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2761055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists - ordered, mutable\n",
    "tech_stocks = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"NVDA\"]\n",
    "print(f\"Tech Stocks: {tech_stocks}\")\n",
    "print(f\"First stock: {tech_stocks[0]}\")\n",
    "tech_stocks.append(\"META\")\n",
    "print(f\"After adding META: {tech_stocks}\")\n",
    "\n",
    "# Dictionaries - key-value pairs\n",
    "stock_prices = {\n",
    "    \"AAPL\": 195.42,\n",
    "    \"MSFT\": 420.55,\n",
    "    \"GOOGL\": 178.89\n",
    "}\n",
    "print(f\"\\nApple stock price: ${stock_prices['AAPL']}\")\n",
    "\n",
    "# Update a value\n",
    "stock_prices[\"AAPL\"] = 196.50\n",
    "print(f\"Updated Apple price: ${stock_prices['AAPL']}\")\n",
    "\n",
    "# Tuples - immutable\n",
    "stock_info = (\"AAPL\", 195.42, 100)  # (ticker, price, shares)\n",
    "print(f\"\\nStock info (tuple): {stock_info}\")\n",
    "\n",
    "# Sets - unique values\n",
    "portfolio = {\"AAPL\", \"MSFT\", \"GOOGL\", \"AAPL\"}  # Note the duplicate AAPL\n",
    "print(f\"\\nUnique stocks in portfolio: {portfolio}\")  # AAPL appears only once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb4ceae",
   "metadata": {},
   "source": [
    "### Control Flow\n",
    "\n",
    "Python uses indentation (whitespace) to define code blocks, which is different from many other programming languages that use braces.\n",
    "\n",
    "#### Conditional Statements (if-elif-else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488fea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price = 195.42\n",
    "buy_threshold = 200.00\n",
    "sell_threshold = 180.00\n",
    "\n",
    "if stock_price > buy_threshold:\n",
    "    action = \"SELL\"\n",
    "    reason = \"Price above buy threshold\"\n",
    "elif stock_price < sell_threshold:\n",
    "    action = \"BUY\"\n",
    "    reason = \"Price below sell threshold\"\n",
    "else:\n",
    "    action = \"HOLD\"\n",
    "    reason = \"Price within target range\"\n",
    "    \n",
    "print(f\"Recommended action: {action}\")\n",
    "print(f\"Reason: {reason}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6002dd94",
   "metadata": {},
   "source": [
    "#### Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a057c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop example with a list\n",
    "print(\"Looping through stocks:\")\n",
    "for stock in tech_stocks:\n",
    "    print(f\"- {stock}\")\n",
    "\n",
    "# For loop with range\n",
    "print(\"\\nCalculating 5-day moving average:\")\n",
    "daily_prices = [195.42, 196.10, 194.89, 197.20, 198.35]\n",
    "total = 0\n",
    "\n",
    "for i in range(len(daily_prices)):\n",
    "    total += daily_prices[i]\n",
    "    print(f\"Day {i+1}: ${daily_prices[i]:.2f}\")\n",
    "\n",
    "moving_average = total / len(daily_prices)\n",
    "print(f\"5-day moving average: ${moving_average:.2f}\")\n",
    "\n",
    "# While loop example\n",
    "print(\"\\nSimulating price changes until threshold:\")\n",
    "current_price = 195.42\n",
    "target_price = 200.00\n",
    "days = 0\n",
    "daily_increase = 0.5\n",
    "\n",
    "while current_price < target_price:\n",
    "    days += 1\n",
    "    current_price += daily_increase\n",
    "    print(f\"Day {days}: ${current_price:.2f}\")\n",
    "    \n",
    "    # Safety exit condition\n",
    "    if days > 10:\n",
    "        break\n",
    "\n",
    "print(f\"Reached target in {days} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a991d56",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "Functions are reusable blocks of code that perform specific tasks. They help make your code more modular and maintainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0be55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to calculate return on investment\n",
    "def calculate_roi(initial_investment, current_value):\n",
    "    \"\"\"\n",
    "    Calculate the return on investment (ROI) as a percentage.\n",
    "    \n",
    "    Args:\n",
    "        initial_investment: The initial amount invested\n",
    "        current_value: The current value of the investment\n",
    "        \n",
    "    Returns:\n",
    "        The ROI as a percentage\n",
    "    \"\"\"\n",
    "    roi = (current_value - initial_investment) / initial_investment * 100\n",
    "    return roi\n",
    "\n",
    "# Using the function\n",
    "initial_investment = 10000\n",
    "current_value = 12500\n",
    "\n",
    "roi = calculate_roi(initial_investment, current_value)\n",
    "print(f\"Initial Investment: ${initial_investment}\")\n",
    "print(f\"Current Value: ${current_value}\")\n",
    "print(f\"ROI: {roi:.2f}%\")\n",
    "\n",
    "# Function with default parameters\n",
    "def calculate_future_value(principal, rate=0.05, years=5):\n",
    "    \"\"\"\n",
    "    Calculate the future value of an investment.\n",
    "    \n",
    "    Args:\n",
    "        principal: Initial investment amount\n",
    "        rate: Annual interest rate (default: 5%)\n",
    "        years: Investment period in years (default: 5)\n",
    "        \n",
    "    Returns:\n",
    "        The future value of the investment\n",
    "    \"\"\"\n",
    "    return principal * (1 + rate) ** years\n",
    "\n",
    "# Using default parameters\n",
    "future_value = calculate_future_value(10000)\n",
    "print(f\"\\nFuture value with default parameters: ${future_value:.2f}\")\n",
    "\n",
    "# Overriding default parameters\n",
    "future_value = calculate_future_value(10000, rate=0.07, years=10)\n",
    "print(f\"Future value with 7% for 10 years: ${future_value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f1b3b5",
   "metadata": {},
   "source": [
    "## 2. NumPy Fundamentals\n",
    "\n",
    "[NumPy](https://numpy.org/) is a fundamental package for scientific computing in Python. It provides support for arrays, matrices, and many mathematical functions to operate on these data structures.\n",
    "\n",
    "Let's start by importing NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f99f715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check NumPy version\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaeef67",
   "metadata": {},
   "source": [
    "### Creating NumPy Arrays\n",
    "\n",
    "NumPy arrays are the core data structure in NumPy. Unlike Python lists, NumPy arrays are homogeneous (all elements have the same data type) and provide efficient operations on large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a16a829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating arrays from Python lists\n",
    "daily_returns = np.array([0.01, -0.005, 0.02, -0.01, 0.015])\n",
    "print(f\"Daily returns: {daily_returns}\")\n",
    "print(f\"Type: {type(daily_returns)}\")\n",
    "print(f\"Shape: {daily_returns.shape}\")\n",
    "print(f\"Data type: {daily_returns.dtype}\")\n",
    "\n",
    "# Creating arrays with specific values\n",
    "zeros_array = np.zeros(5)\n",
    "ones_array = np.ones(5)\n",
    "filled_array = np.full(5, 0.05)\n",
    "\n",
    "print(\"\\nArrays with specific values:\")\n",
    "print(f\"Zeros: {zeros_array}\")\n",
    "print(f\"Ones: {ones_array}\")\n",
    "print(f\"Filled with 0.05: {filled_array}\")\n",
    "\n",
    "# Creating sequences\n",
    "sequence = np.arange(0, 1.1, 0.2)  # Start, stop, step\n",
    "linspace = np.linspace(0, 1, 6)     # Start, stop, num\n",
    "\n",
    "print(\"\\nSequences:\")\n",
    "print(f\"arange(0, 1.1, 0.2): {sequence}\")\n",
    "print(f\"linspace(0, 1, 6): {linspace}\")\n",
    "\n",
    "# Random arrays\n",
    "random_uniform = np.random.rand(5)       # Uniform distribution [0, 1)\n",
    "random_normal = np.random.randn(5)       # Standard normal distribution\n",
    "random_integers = np.random.randint(1, 11, 5)  # Random integers [1, 10]\n",
    "\n",
    "print(\"\\nRandom arrays:\")\n",
    "print(f\"Uniform [0, 1): {random_uniform}\")\n",
    "print(f\"Normal: {random_normal}\")\n",
    "print(f\"Integers [1, 10]: {random_integers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2364ee33",
   "metadata": {},
   "source": [
    "### Multi-dimensional Arrays\n",
    "\n",
    "NumPy can work with arrays of any dimension. In finance, we often use:\n",
    "- 1D arrays for time series (e.g., stock prices over time)\n",
    "- 2D arrays for matrices (e.g., portfolio returns, correlation matrices)\n",
    "- 3D+ arrays for more complex data (e.g., multiple asset returns across time and scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d712e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a 2D array (matrix) - Stock prices for 3 stocks over 5 days\n",
    "stock_prices = np.array([\n",
    "    [150.25, 151.30, 149.80, 152.50, 153.75],  # Stock A\n",
    "    [200.50, 199.75, 202.00, 198.50, 203.25],  # Stock B\n",
    "    [95.75, 97.25, 96.50, 98.00, 97.50]        # Stock C\n",
    "])\n",
    "\n",
    "print(f\"Stock prices shape: {stock_prices.shape}\")  # (3, 5) - 3 stocks, 5 days\n",
    "print(\"Stock prices matrix:\")\n",
    "print(stock_prices)\n",
    "\n",
    "# Accessing elements\n",
    "print(f\"\\nPrice of Stock A on day 1: {stock_prices[0, 0]}\")\n",
    "print(f\"Prices of Stock B for all days: {stock_prices[1]}\")\n",
    "print(f\"Prices of all stocks on day 3: {stock_prices[:, 2]}\")\n",
    "\n",
    "# Reshaping arrays\n",
    "daily_returns = np.array([0.01, -0.005, 0.02, -0.01, 0.015, 0.008, -0.003, 0.012])\n",
    "reshaped = daily_returns.reshape(2, 4)  # Reshape to 2 rows, 4 columns\n",
    "\n",
    "print(\"\\nOriginal daily returns:\")\n",
    "print(daily_returns)\n",
    "print(\"\\nReshaped (2x4):\")\n",
    "print(reshaped)\n",
    "\n",
    "# Creating a 3D array - Multiple portfolio scenarios\n",
    "# 2 portfolios, 3 stocks, 4 time periods\n",
    "portfolio_scenarios = np.random.randn(2, 3, 4) * 0.01 + 0.005  # Mean: 0.5%, SD: 1%\n",
    "\n",
    "print(\"\\n3D array shape:\", portfolio_scenarios.shape)\n",
    "print(\"First portfolio, all stocks, all time periods:\")\n",
    "print(portfolio_scenarios[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a76602",
   "metadata": {},
   "source": [
    "### Vectorized Operations\n",
    "\n",
    "One of the key advantages of NumPy is its ability to perform operations on entire arrays without explicit loops, which is much faster than Python's native looping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c03445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic arithmetic operations\n",
    "returns = np.array([0.01, 0.02, -0.01, 0.03, -0.02])\n",
    "\n",
    "# Addition\n",
    "returns_plus_1 = returns + 1  # Add 1 to each element\n",
    "print(\"Returns + 1:\", returns_plus_1)\n",
    "\n",
    "# Element-wise multiplication\n",
    "doubled_returns = returns * 2\n",
    "print(\"Doubled returns:\", doubled_returns)\n",
    "\n",
    "# Calculate compound returns\n",
    "compound_returns = np.cumprod(returns + 1) - 1\n",
    "print(\"Compound returns:\", compound_returns)\n",
    "\n",
    "# Statistical operations\n",
    "print(\"\\nStatistical measures:\")\n",
    "print(f\"Mean return: {np.mean(returns):.4f}\")\n",
    "print(f\"Standard deviation: {np.std(returns):.4f}\")\n",
    "print(f\"Minimum return: {np.min(returns):.4f}\")\n",
    "print(f\"Maximum return: {np.max(returns):.4f}\")\n",
    "\n",
    "# Broadcasting - operations between arrays of different shapes\n",
    "# Example: Calculating daily returns for 3 stocks with different initial prices\n",
    "prices = np.array([100, 200, 50])  # Initial prices\n",
    "daily_changes = np.array([0.01, -0.005, 0.02, 0.015, -0.01])  # Daily percentage changes\n",
    "\n",
    "# Broadcasting the daily changes across all stocks\n",
    "# Each row represents a stock, each column a day\n",
    "daily_returns_matrix = np.outer(prices, daily_changes)\n",
    "print(\"\\nDaily price changes matrix:\")\n",
    "print(daily_returns_matrix)\n",
    "\n",
    "# Calculate new prices for each day (assuming compounding)\n",
    "price_matrix = np.zeros((len(prices), len(daily_changes) + 1))\n",
    "price_matrix[:, 0] = prices  # Set initial prices\n",
    "\n",
    "for day in range(len(daily_changes)):\n",
    "    price_matrix[:, day + 1] = price_matrix[:, day] * (1 + daily_changes[day])\n",
    "\n",
    "print(\"\\nPrice evolution matrix:\")\n",
    "print(price_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d02d5c",
   "metadata": {},
   "source": [
    "### Linear Algebra with NumPy\n",
    "\n",
    "NumPy provides efficient implementations of linear algebra operations, which are crucial for financial modeling and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dae44d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix operations\n",
    "# Example: Portfolio allocation and returns\n",
    "\n",
    "# Stock returns for 3 stocks over 5 days\n",
    "stock_returns = np.array([\n",
    "    [0.01, -0.005, 0.02, -0.01, 0.015],  # Stock A\n",
    "    [0.02, -0.01, 0.01, 0.02, -0.005],   # Stock B\n",
    "    [0.005, 0.01, -0.005, 0.01, 0.02]    # Stock C\n",
    "])\n",
    "\n",
    "# Portfolio weights\n",
    "weights = np.array([0.5, 0.3, 0.2])  # 50% in A, 30% in B, 20% in C\n",
    "\n",
    "# Calculate portfolio returns for each day\n",
    "portfolio_returns = np.dot(weights, stock_returns)\n",
    "print(\"Portfolio daily returns:\")\n",
    "print(portfolio_returns)\n",
    "\n",
    "# Calculate the covariance matrix of returns\n",
    "cov_matrix = np.cov(stock_returns)\n",
    "print(\"\\nCovariance matrix of returns:\")\n",
    "print(cov_matrix)\n",
    "\n",
    "# Calculate portfolio variance using matrix multiplication\n",
    "portfolio_variance = np.dot(weights, np.dot(cov_matrix, weights))\n",
    "print(f\"\\nPortfolio variance: {portfolio_variance:.6f}\")\n",
    "print(f\"Portfolio volatility (annualized): {np.sqrt(252 * portfolio_variance):.4f}\")\n",
    "\n",
    "# Generating random matrices for correlation\n",
    "# Let's create a correlation matrix for 5 assets\n",
    "np.random.seed(42)  # For reproducibility\n",
    "n_assets = 5\n",
    "\n",
    "# Start with random data\n",
    "data = np.random.randn(100, n_assets)  # 100 days of returns for 5 assets\n",
    "corr_matrix = np.corrcoef(data.T)  # Transpose to get correlation between assets\n",
    "\n",
    "print(\"\\nCorrelation matrix for 5 assets:\")\n",
    "print(np.round(corr_matrix, 2))  # Rounded for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ec8ae2",
   "metadata": {},
   "source": [
    "## 3. PyTorch Introduction\n",
    "\n",
    "[PyTorch](https://pytorch.org/) is a popular deep learning framework that provides:\n",
    "1. Tensor computation with strong GPU acceleration\n",
    "2. Automatic differentiation for building neural networks\n",
    "3. High-level APIs for training and deployment\n",
    "\n",
    "Let's start by importing PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0d29e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check PyTorch version and GPU availability\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95385b3",
   "metadata": {},
   "source": [
    "### PyTorch Tensors\n",
    "\n",
    "Tensors are the fundamental data structure in PyTorch, similar to NumPy arrays but with additional capabilities for deep learning.\n",
    "\n",
    "A tensor's dimensionality refers to the number of indices required to reference an element:\n",
    "- 0D tensor (scalar): A single value\n",
    "- 1D tensor (vector): A sequence of values\n",
    "- 2D tensor (matrix): A table of values\n",
    "- 3D tensor: A cube of values\n",
    "- Higher dimensions: More complex arrangements\n",
    "\n",
    "In deep learning for finance, tensors can represent:\n",
    "- Stock prices over time\n",
    "- Financial features for multiple assets\n",
    "- Embeddings of financial text\n",
    "- Neural network weights and gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f62e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tensors\n",
    "# From Python lists\n",
    "scalar = torch.tensor(42)\n",
    "vector = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "matrix = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "print(\"Scalar tensor:\", scalar, \"Shape:\", scalar.shape)\n",
    "print(\"Vector tensor:\", vector, \"Shape:\", vector.shape)\n",
    "print(\"Matrix tensor:\", matrix, \"Shape:\", matrix.shape)\n",
    "\n",
    "# From NumPy arrays\n",
    "np_array = np.array([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]])\n",
    "tensor_from_np = torch.from_numpy(np_array)\n",
    "print(\"\\nTensor from NumPy:\", tensor_from_np)\n",
    "\n",
    "# Creating tensors with specific values\n",
    "zeros = torch.zeros(2, 3)\n",
    "ones = torch.ones(2, 3)\n",
    "rand = torch.rand(2, 3)  # Random uniform [0, 1)\n",
    "randn = torch.randn(2, 3)  # Random normal (mean=0, std=1)\n",
    "\n",
    "print(\"\\nZeros tensor:\")\n",
    "print(zeros)\n",
    "print(\"\\nRandom normal tensor:\")\n",
    "print(randn)\n",
    "\n",
    "# Example: Creating tensors to represent financial data\n",
    "# Daily stock prices for 3 stocks over 5 days\n",
    "stock_prices_tensor = torch.tensor([\n",
    "    [150.25, 151.30, 149.80, 152.50, 153.75],  # Stock A\n",
    "    [200.50, 199.75, 202.00, 198.50, 203.25],  # Stock B\n",
    "    [95.75, 97.25, 96.50, 98.00, 97.50]        # Stock C\n",
    "], dtype=torch.float)\n",
    "\n",
    "print(\"\\nStock prices tensor:\")\n",
    "print(stock_prices_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ccc459",
   "metadata": {},
   "source": [
    "### Tensor Operations\n",
    "\n",
    "PyTorch provides a rich set of operations for manipulating tensors, which are essential for building and training neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0bff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic operations\n",
    "a = torch.tensor([1, 2, 3], dtype=torch.float)\n",
    "b = torch.tensor([4, 5, 6], dtype=torch.float)\n",
    "\n",
    "# Addition\n",
    "c = a + b  # or torch.add(a, b)\n",
    "print(\"a + b =\", c)\n",
    "\n",
    "# Multiplication (element-wise)\n",
    "d = a * b  # or torch.mul(a, b)\n",
    "print(\"a * b =\", d)\n",
    "\n",
    "# Matrix multiplication\n",
    "m1 = torch.tensor([[1, 2], [3, 4]], dtype=torch.float)\n",
    "m2 = torch.tensor([[5, 6], [7, 8]], dtype=torch.float)\n",
    "m3 = torch.matmul(m1, m2)  # or m1 @ m2\n",
    "print(\"\\nMatrix multiplication:\")\n",
    "print(m3)\n",
    "\n",
    "# Financial example: Portfolio returns calculation\n",
    "weights = torch.tensor([0.5, 0.3, 0.2])  # Portfolio weights\n",
    "daily_returns = torch.tensor([\n",
    "    [0.01, 0.02, 0.005],  # Day 1 returns for 3 stocks\n",
    "    [-0.005, -0.01, 0.01],  # Day 2\n",
    "    [0.02, 0.01, -0.005],  # Day 3\n",
    "    [-0.01, 0.02, 0.01],  # Day 4\n",
    "    [0.015, -0.005, 0.02]  # Day 5\n",
    "])\n",
    "\n",
    "# Calculate portfolio returns for each day\n",
    "portfolio_returns = torch.matmul(daily_returns, weights)\n",
    "print(\"\\nPortfolio daily returns:\")\n",
    "print(portfolio_returns)\n",
    "\n",
    "# Reshaping tensors\n",
    "original = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "reshaped = original.reshape(2, 3)\n",
    "print(\"\\nOriginal:\", original)\n",
    "print(\"Reshaped (2x3):\", reshaped)\n",
    "\n",
    "# Tensor slicing (similar to NumPy)\n",
    "print(\"\\nSlicing examples:\")\n",
    "print(\"First row:\", reshaped[0])\n",
    "print(\"First column:\", reshaped[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792b8413",
   "metadata": {},
   "source": [
    "### Automatic Differentiation with PyTorch\n",
    "\n",
    "One of PyTorch's key features is automatic differentiation (autograd), which is essential for training neural networks. The autograd system keeps track of operations performed on tensors and can automatically compute gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dd82fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors with gradient tracking\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = torch.tensor([3.0], requires_grad=True)\n",
    "\n",
    "# Perform operations\n",
    "z = x**2 + y**3\n",
    "\n",
    "# Compute gradients\n",
    "z.backward()\n",
    "\n",
    "# Access gradients\n",
    "print(f\"z = x^2 + y^3 = {z.item()}\")\n",
    "print(f\"dz/dx = 2x = {x.grad.item()}\")\n",
    "print(f\"dz/dy = 3y^2 = {y.grad.item()}\")\n",
    "\n",
    "# Financial example: Computing sensitivity of a portfolio to changes in asset prices\n",
    "# Option pricing sensitivity (Greeks calculation)\n",
    "\n",
    "def black_scholes_call(S, K, T, r, sigma):\n",
    "    \"\"\"Simplified Black-Scholes for a European call option.\"\"\"\n",
    "    import math\n",
    "    \n",
    "    d1 = (torch.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * torch.sqrt(T))\n",
    "    d2 = d1 - sigma * torch.sqrt(T)\n",
    "    \n",
    "    # Using sigmoid approximation for normal CDF\n",
    "    N_d1 = 1 / (1 + torch.exp(-d1 * math.sqrt(2/math.pi)))\n",
    "    N_d2 = 1 / (1 + torch.exp(-d2 * math.sqrt(2/math.pi)))\n",
    "    \n",
    "    return S * N_d1 - K * torch.exp(-r * T) * N_d2\n",
    "\n",
    "# Set up parameters with gradient tracking\n",
    "S = torch.tensor([100.0], requires_grad=True)  # Stock price\n",
    "K = torch.tensor(100.0)  # Strike price\n",
    "T = torch.tensor(1.0)    # Time to maturity (1 year)\n",
    "r = torch.tensor(0.05)   # Risk-free interest rate\n",
    "sigma = torch.tensor(0.2)  # Volatility\n",
    "\n",
    "# Calculate option price\n",
    "option_price = black_scholes_call(S, K, T, r, sigma)\n",
    "print(f\"\\nOption price: ${option_price.item():.2f}\")\n",
    "\n",
    "# Calculate delta (sensitivity to stock price changes)\n",
    "option_price.backward()\n",
    "delta = S.grad.item()\n",
    "print(f\"Delta (dPrice/dStock): {delta:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810891b8",
   "metadata": {},
   "source": [
    "### Neural Network Basics with PyTorch\n",
    "\n",
    "PyTorch provides a high-level API (`torch.nn`) for building neural networks. Here's a simple example of how to define and use a basic neural network for a financial prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298205c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Reset gradients from previous example\n",
    "torch.manual_seed(42)  # For reproducibility\n",
    "\n",
    "# Create a simple dataset: mapping from 2D input to 1D output\n",
    "# Example: Predicting stock return based on 2 features\n",
    "X = torch.randn(100, 2)  # 100 samples, 2 features each (e.g., P/E ratio and dividend yield)\n",
    "# Create a target variable with some pattern plus noise\n",
    "y = 0.5 * X[:, 0] - 0.3 * X[:, 1] + 0.1 * torch.randn(100)  # Linear relationship with noise\n",
    "y = y.unsqueeze(1)  # Reshape to [100, 1]\n",
    "\n",
    "# Define a simple neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(2, 8)  # Input: 2 features, Output: 8 hidden neurons\n",
    "        self.activation = nn.ReLU()     # ReLU activation function\n",
    "        self.layer2 = nn.Linear(8, 1)   # Hidden: 8 neurons, Output: 1 (prediction)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "# Create the model\n",
    "model = SimpleNN()\n",
    "print(\"Model architecture:\")\n",
    "print(model)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Stochastic Gradient Descent\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    y_pred = model(X)\n",
    "    loss = criterion(y_pred, y)\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()  # Clear previous gradients\n",
    "    loss.backward()        # Compute gradients\n",
    "    optimizer.step()       # Update parameters\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# Test the model with new data\n",
    "X_test = torch.tensor([[0.5, 0.2], [-0.3, 0.8], [0.7, -0.4]], dtype=torch.float)\n",
    "with torch.no_grad():  # Disable gradient tracking\n",
    "    y_pred = model(X_test)\n",
    "    print(\"\\nPredictions for test data:\")\n",
    "    print(y_pred)\n",
    "\n",
    "# Calculate expected values based on our generating function\n",
    "y_expected = 0.5 * X_test[:, 0] - 0.3 * X_test[:, 1]\n",
    "print(\"Expected values (without noise):\")\n",
    "print(y_expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8965a466",
   "metadata": {},
   "source": [
    "### Tensors for LLMs and Transformers\n",
    "\n",
    "Large Language Models (LLMs) like GPT and BERT use tensor operations extensively. Here's a simplified example of how tensors are used in the transformer architecture that powers these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d532a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified demonstration of tensor operations in transformers\n",
    "\n",
    "# 1. Word Embeddings: Convert tokens to vectors\n",
    "vocab_size = 10000\n",
    "embedding_dim = 256\n",
    "batch_size = 3\n",
    "seq_length = 5\n",
    "\n",
    "# Create random token indices (words in a sentence)\n",
    "token_indices = torch.randint(0, vocab_size, (batch_size, seq_length))\n",
    "print(\"Token indices (3 sentences, 5 words each):\")\n",
    "print(token_indices)\n",
    "\n",
    "# Embedding layer (convert tokens to vectors)\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "embedded_tokens = embedding(token_indices)\n",
    "print(f\"\\nEmbedded tokens shape: {embedded_tokens.shape}\")  # [batch_size, seq_length, embedding_dim]\n",
    "print(\"First token embedding (first 5 values):\")\n",
    "print(embedded_tokens[0, 0, :5])  # Show first 5 dimensions of first token embedding\n",
    "\n",
    "# 2. Self-Attention Mechanism (simplified)\n",
    "# In self-attention, we compute how each token attends to all other tokens\n",
    "\n",
    "# Linear projections for query, key, value\n",
    "head_dim = 64\n",
    "query = torch.randn(batch_size, seq_length, head_dim)\n",
    "key = torch.randn(batch_size, seq_length, head_dim)\n",
    "value = torch.randn(batch_size, seq_length, head_dim)\n",
    "\n",
    "# Compute attention scores (simplified)\n",
    "# Actual implementation uses scaled dot-product attention\n",
    "attention_scores = torch.bmm(query, key.transpose(1, 2))\n",
    "print(f\"\\nAttention scores shape: {attention_scores.shape}\")  # [batch_size, seq_length, seq_length]\n",
    "\n",
    "# Apply softmax to get attention weights\n",
    "attention_weights = torch.softmax(attention_scores / (head_dim ** 0.5), dim=-1)\n",
    "print(\"\\nAttention weights (first sample):\")\n",
    "print(attention_weights[0])\n",
    "\n",
    "# Apply attention weights to values\n",
    "attention_output = torch.bmm(attention_weights, value)\n",
    "print(f\"\\nAttention output shape: {attention_output.shape}\")  # [batch_size, seq_length, head_dim]\n",
    "\n",
    "# 3. Feed-Forward Neural Network (simplified)\n",
    "# Each position is processed independently by the same feedforward network\n",
    "ff_layer1 = nn.Linear(head_dim, 512)\n",
    "ff_layer2 = nn.Linear(512, head_dim)\n",
    "ff_activation = nn.ReLU()\n",
    "\n",
    "# Process the attention output\n",
    "ff_output = ff_layer2(ff_activation(ff_layer1(attention_output)))\n",
    "print(f\"\\nFeed-forward output shape: {ff_output.shape}\")  # Same as attention output\n",
    "\n",
    "# This is a highly simplified version of the operations in transformer models.\n",
    "# Actual implementations include layer normalization, residual connections,\n",
    "# multiple attention heads, and many more layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05b8d3e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this crash course, we've covered:\n",
    "\n",
    "1. **Python Basics**\n",
    "   - Variables, data types, and control structures\n",
    "   - Data structures (lists, dictionaries, tuples, sets)\n",
    "   - Functions and modules\n",
    "\n",
    "2. **NumPy Fundamentals**\n",
    "   - Creating and manipulating arrays\n",
    "   - Vectorized operations for efficient computation\n",
    "   - Linear algebra basics for financial applications\n",
    "\n",
    "3. **PyTorch Introduction**\n",
    "   - Tensors and operations\n",
    "   - Automatic differentiation\n",
    "   - Building basic neural networks\n",
    "   - Tensor operations in transformer models\n",
    "\n",
    "These concepts form the foundation for working with Large Language Models in finance. As you progress through this course, you'll build on these fundamentals to develop more sophisticated AI applications for financial analysis, prediction, and decision-making.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Practice with real financial data\n",
    "- Explore more advanced neural network architectures\n",
    "- Learn about natural language processing techniques for financial text\n",
    "- Dive deeper into transformer models and their applications in finance"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
